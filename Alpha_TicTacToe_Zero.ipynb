{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd95df06ad6614d8ea31ce2c635a29972",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5236111213050683"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "import torch\n",
    "from alpha_zero.utils import eval_winrate\n",
    "from alpha_zero.models import RolloutPolicy, Model, Backbone, ValueFunction, NNTreePolicy, TreePolicy\n",
    "from alpha_zero.mcts import mcts, Node, get_ns, get_qs, get_best_action\n",
    "from alpha_zero.augmentations_tictactoe import symetric_add2rbuff\n",
    "from myrl.buffers import ReplayBuffer\n",
    "from myrl.utils import ExperimentWriter\n",
    "from gym_tictactoe.env import TicTacToeEnv, agent_by_mark, next_mark\n",
    "import copy\n",
    "from alpha_zero.utils import play_mcts_against_human, play_mcts_against_itself, save, load\n",
    "\n",
    "\n",
    "env = TicTacToeEnv()\n",
    "obs = env.reset()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import math\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_policy = RolloutPolicy(env)\n",
    "model = Model(TicTacToeEnv())\n",
    "backbone = Backbone([10, 32])\n",
    "value_function = ValueFunction([32, 16, 1], backbone=backbone)\n",
    "tree_policy = NNTreePolicy([32, 16, 9], backbone=backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.49, 0.06, 0.45)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "eval_winrate(rollout_policy, tree_policy, TicTacToeEnv(), model, n_games=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_policy = copy.deepcopy(tree_policy)\n",
    "wll = ExperimentWriter('tb/alpha_tictacte_zero_with_vfunc_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7193\n",
      "278 winrate= 0.56 0.12\n",
      "loss= 0.0050238193944096565 0.005008228588849306 1.5590823750244454e-05\n",
      "279 winrate= 0.61 0.08\n",
      "loss= 0.005001746583729982 0.004994604270905256 7.1421254688175395e-06\n",
      "280 winrate= 0.57 0.05\n",
      "loss= 0.004980285651981831 0.004937073215842247 4.321230881032534e-05\n",
      "281 winrate= 0.63 0.07\n",
      "loss= 0.004934994969516993 0.00490149250254035 3.350228143972345e-05\n",
      "282 winrate= 0.58 0.08\n",
      "loss= 0.004818437620997429 0.0048089646734297276 9.472805686527863e-06\n",
      "283 winrate= 0.61 0.05\n",
      "loss= 0.00483403354883194 0.004808552097529173 2.5481491320533678e-05\n",
      "284 winrate= 0.59 0.05\n",
      "loss= 0.005052801687270403 0.005049074999988079 3.726638851730968e-06\n",
      "285 winrate= 0.62 0.08\n",
      "loss= 0.0049452693201601505 0.004930158611387014 1.5110685126273893e-05\n",
      "286 winrate= 0.54 0.06\n",
      "loss= 0.004843760281801224 0.004831216298043728 1.2543925549834967e-05\n",
      "287 winrate= 0.65 0.03\n",
      "loss= 0.004918344784528017 0.004868274088948965 5.007081927033141e-05\n",
      "288 winrate= 0.54 0.06\n",
      "loss= 0.0048578944988548756 0.004777726251631975 8.016838546609506e-05\n",
      "289 winrate= 0.65 0.07\n",
      "loss= 0.004911257419735193 0.004900339059531689 1.0918301086348947e-05\n",
      "290 winrate= 0.64 0.07\n",
      "loss= 0.004921237006783485 0.004876078572124243 4.515836189966649e-05\n",
      "291 winrate= 0.58 0.1\n",
      "loss= 0.004792319610714912 0.0047585684806108475 3.375130836502649e-05\n",
      "292 winrate= 0.53 0.1\n",
      "loss= 0.004921210929751396 0.00484752980992198 7.368119986495003e-05\n",
      "293 winrate= 0.66 0.07\n",
      "loss= 0.005095853470265865 0.004959762096405029 0.00013609131565317512\n",
      "294 winrate= 0.59 0.09\n",
      "loss= 0.005058152135461569 0.004747004248201847 0.0003111478581558913\n",
      "295 winrate= 0.6 0.06\n",
      "loss= 0.005020997487008572 0.0048033706843853 0.0002176265697926283\n",
      "296 winrate= 0.56 0.1\n",
      "loss= 0.005084159318357706 0.004928705282509327 0.00015545383212156594\n",
      "297 winrate= 0.55 0.13\n",
      "loss= 0.0048512425273656845 0.0048320963978767395 1.9146160411764868e-05\n",
      "298 winrate= 0.68 0.03\n",
      "loss= 0.0049659013748168945 0.004787156358361244 0.00017874513287097216\n",
      "299 winrate= 0.61 0.07\n",
      "loss= 0.004909736104309559 0.004751219879835844 0.00015851613716222346\n",
      "300 winrate= 0.62 0.09\n",
      "loss= 0.004911772441118956 0.0048497505486011505 6.202203076099977e-05\n",
      "301 winrate= 0.61 0.08\n",
      "loss= 0.005087479017674923 0.005047938786447048 3.954002386308275e-05\n",
      "302 winrate= 0.6 0.06\n",
      "loss= 0.004922167398035526 0.004898211918771267 2.3955599317559972e-05\n",
      "303 winrate= 0.57 0.07\n",
      "loss= 0.004962468519806862 0.004946707747876644 1.5760728274472058e-05\n",
      "304 winrate= 0.64 0.04\n",
      "loss= 0.004807470366358757 0.004791480954736471 1.598962080606725e-05\n",
      "305 winrate= 0.64 0.08\n",
      "loss= 0.0047257933765649796 0.004714170005172491 1.1623424143181182e-05\n",
      "306 winrate= 0.64 0.04\n",
      "loss= 0.004758215509355068 0.004756172187626362 2.0433640202099923e-06\n",
      "307 winrate= 0.66 0.07\n",
      "loss= 0.00493871932849288 0.004932333715260029 6.385770120687084e-06\n",
      "308 winrate= 0.58 0.07\n",
      "loss= 0.004998406395316124 0.004973754286766052 2.4652112188050523e-05\n",
      "309 winrate= 0.61 0.06\n",
      "loss= 0.0052400510758161545 0.005034825298935175 0.0002052258641924709\n",
      "310 winrate= 0.54 0.06\n",
      "loss= 0.00525319017469883 0.00509895384311676 0.00015423634613398463\n",
      "311 winrate= 0.52 0.08\n",
      "loss= 0.004716651514172554 0.0046578673645854 5.878416413906962e-05\n",
      "312 winrate= 0.56 0.08\n",
      "loss= 0.00484530720859766 0.004839171655476093 6.135712283139583e-06\n",
      "313 winrate= 0.57 0.02\n",
      "loss= 0.0050710770301520824 0.004976099357008934 9.497751307208091e-05\n",
      "314 winrate= 0.61 0.07\n",
      "loss= 0.004840154200792313 0.004832536447793245 7.617695700901095e-06\n",
      "315 winrate= 0.63 0.09\n",
      "loss= 0.004987499676644802 0.004919378086924553 6.812166247982532e-05\n",
      "316 winrate= 0.64 0.05\n",
      "loss= 0.0051627326756715775 0.004891510121524334 0.00027122243773192167\n",
      "317 winrate= 0.61 0.1\n",
      "loss= 0.0049034119583666325 0.004831262398511171 7.214958168333396e-05\n",
      "318 winrate= 0.66 0.05\n",
      "loss= 0.004938265308737755 0.004892353434115648 4.591191100189462e-05\n",
      "319 winrate= 0.64 0.05\n",
      "loss= 0.005008942913264036 0.004942787811160088 6.615518941543996e-05\n",
      "320 winrate= 0.55 0.05\n",
      "loss= 0.0049035497941076756 0.004900628235191107 2.9217335395514965e-06\n",
      "321 winrate= 0.61 0.03\n",
      "loss= 0.004858896601945162 0.004834694322198629 2.4202343411161564e-05\n",
      "322 winrate= 0.55 0.09\n",
      "loss= 0.005004823673516512 0.0049636708572506905 4.115280898986384e-05\n",
      "323 winrate= 0.6 0.08\n",
      "loss= 0.004858625587075949 0.004766771104186773 9.185446106130257e-05\n",
      "324 winrate= 0.55 0.06\n",
      "loss= 0.004885280039161444 0.004735154565423727 0.00015012534277047962\n",
      "325 winrate= 0.66 0.08\n",
      "loss= 0.0049699884839355946 0.004848427604883909 0.00012156067532487214\n",
      "326 winrate= 0.62 0.06\n",
      "loss= 0.004911582916975021 0.0048864008858799934 2.518211113056168e-05\n",
      "327 winrate= 0.62 0.07\n",
      "loss= 0.005122373811900616 0.004944286309182644 0.0001780873426469043\n",
      "328 winrate= 0.58 0.01\n",
      "loss= 0.005261101759970188 0.0048986636102199554 0.00036243797512724996\n",
      "329 winrate= 0.57 0.08\n",
      "loss= 0.0051771532744169235 0.005036520306020975 0.00014063289563637227\n",
      "330 winrate= 0.53 0.08\n",
      "loss= 0.004889360629022121 0.004836404230445623 5.295631490298547e-05\n",
      "331 winrate= 0.67 0.05\n",
      "loss= 0.004906784743070602 0.004843385424464941 6.339929677778855e-05\n",
      "332 winrate= 0.61 0.07\n",
      "loss= 0.004918023943901062 0.004819042980670929 9.898106509353966e-05\n",
      "333 winrate= 0.68 0.06\n",
      "loss= 0.005028896499425173 0.004947437904775143 8.145854371832684e-05\n",
      "334 winrate= 0.6 0.02\n",
      "loss= 0.004913385026156902 0.004863447044044733 4.993781476514414e-05\n",
      "335 winrate= 0.58 0.03\n",
      "loss= 0.004988440778106451 0.004924836102873087 6.360461702570319e-05\n",
      "336 winrate= 0.55 0.05\n",
      "loss= 0.005271368194371462 0.005163536407053471 0.00010783175093820319\n",
      "337 winrate= 0.6 0.05\n",
      "loss= 0.005040493793785572 0.004919982515275478 0.00012051137309754267\n",
      "338 winrate= 0.63 0.05\n",
      "loss= 0.005090177059173584 0.005080784671008587 9.392580977873877e-06\n",
      "339 winrate= 0.63 0.07\n",
      "loss= 0.004721371922641993 0.004718524403870106 2.8473587008193135e-06\n",
      "340 winrate= 0.64 0.06\n",
      "loss= 0.0049515459686517715 0.0049278950318694115 2.3651047740713693e-05\n",
      "341 winrate= 0.63 0.04\n",
      "loss= 0.004941415507346392 0.004931354895234108 1.0060458407679107e-05\n",
      "342 winrate= 0.62 0.02\n",
      "loss= 0.004845458082854748 0.004841573536396027 3.884376383211929e-06\n",
      "343 winrate= 0.54 0.11\n",
      "loss= 0.00496465340256691 0.004939313046634197 2.5340208594570868e-05\n",
      "344 winrate= 0.62 0.08\n",
      "loss= 0.004944330547004938 0.004876412451267242 6.791789928684011e-05\n",
      "345 winrate= 0.68 0.06\n",
      "loss= 0.004937566816806793 0.0048965951427817345 4.097184137208387e-05\n",
      "346 winrate= 0.59 0.05\n",
      "loss= 0.004859840963035822 0.004699073266237974 0.000160767522174865\n",
      "347 winrate= 0.58 0.07\n",
      "loss= 0.00507543608546257 0.005009602755308151 6.583314097952098e-05\n",
      "348 winrate= 0.55 0.05\n",
      "loss= 0.005000538192689419 0.004882824141532183 0.000117714203952346\n",
      "349 winrate= 0.56 0.07\n",
      "loss= 0.00516965938732028 0.00495884520933032 0.00021081423619762063\n",
      "350 winrate= 0.62 0.06\n",
      "loss= 0.004941134247928858 0.0049134413711726665 2.7692940420820378e-05\n",
      "351 winrate= 0.7 0.08\n",
      "loss= 0.00544125447049737 0.005146074574440718 0.0002951797505374998\n",
      "352 winrate= 0.55 0.09\n",
      "loss= 0.005047105252742767 0.004874202888458967 0.00017290256801061332\n",
      "353 winrate= 0.56 0.07\n",
      "loss= 0.005223862361162901 0.005138915963470936 8.494643407175317e-05\n",
      "354 winrate= 0.64 0.07\n",
      "loss= 0.005067571997642517 0.0050230068154633045 4.4565113057615235e-05\n",
      "355 winrate= 0.58 0.07\n",
      "loss= 0.005006559193134308 0.004991734400391579 1.4824945537839085e-05\n",
      "356 winrate= 0.69 0.03\n",
      "loss= 0.0050020767375826836 0.004995869938284159 6.206710622791434e-06\n",
      "357 winrate= 0.58 0.06\n",
      "loss= 0.004704906139522791 0.004702241625636816 2.664686689968221e-06\n",
      "358 winrate= 0.62 0.04\n",
      "loss= 0.004933319520205259 0.004925624467432499 7.694876330788247e-06\n",
      "359 winrate= 0.53 0.08\n",
      "loss= 0.005247756838798523 0.005236841272562742 1.0915338862105273e-05\n",
      "360 winrate= 0.66 0.05\n",
      "loss= 0.004942992236465216 0.004937289748340845 5.702324870071607e-06\n",
      "361 winrate= 0.56 0.06\n",
      "loss= 0.004981806501746178 0.004918256774544716 6.354977813316509e-05\n",
      "362 winrate= 0.71 0.05\n",
      "loss= 0.004916410893201828 0.0048966617323458195 1.9749302737182006e-05\n",
      "363 winrate= 0.64 0.04\n",
      "loss= 0.00486103305593133 0.004770250059664249 9.078295261133462e-05\n",
      "364 winrate= 0.69 0.07\n",
      "loss= 0.004906987305730581 0.004773927852511406 0.0001330594386672601\n",
      "365 winrate= 0.59 0.05\n",
      "loss= 0.00502612441778183 0.004851571284234524 0.0001745531480992213\n",
      "366 winrate= 0.6 0.06\n",
      "loss= 0.005121220368891954 0.005007045343518257 0.00011417506902944297\n",
      "367 winrate= 0.56 0.06\n",
      "loss= 0.005010811612010002 0.00495909946039319 5.1711936976062134e-05\n",
      "368 winrate= 0.61 0.03\n",
      "loss= 0.00508840149268508 0.0049379738047719 0.00015042757149785757\n",
      "369 winrate= 0.58 0.09\n",
      "loss= 0.004924953915178776 0.00486313970759511 6.18143385509029e-05\n",
      "370 winrate= 0.6 0.1\n",
      "loss= 0.005120419897139072 0.005083895288407803 3.6524448660202324e-05\n",
      "371 winrate= 0.55 0.05\n",
      "loss= 0.005025297403335571 0.0049517047591507435 7.359246956184506e-05\n",
      "372 winrate= 0.64 0.06\n",
      "loss= 0.00519392266869545 0.005054761655628681 0.00013916102761868387\n",
      "373 winrate= 0.57 0.04\n",
      "loss= 0.004929256625473499 0.004910759162157774 1.849733234848827e-05\n",
      "374 winrate= 0.58 0.1\n",
      "loss= 0.0050054327584803104 0.004955262877047062 5.016974682803266e-05\n",
      "375 winrate= 0.63 0.08\n",
      "loss= 0.004822541959583759 0.004789590369910002 3.295174246886745e-05\n",
      "376 winrate= 0.63 0.04\n",
      "loss= 0.004977973643690348 0.00497364392504096 4.329515377321513e-06\n",
      "377 winrate= 0.7 0.07\n",
      "loss= 0.0048936279490590096 0.004865215625613928 2.8412468964233994e-05\n",
      "378 winrate= 0.64 0.08\n",
      "loss= 0.004960558842867613 0.004954454954713583 6.104081876401324e-06\n",
      "379 winrate= 0.64 0.06\n",
      "loss= 0.00492723798379302 0.004891666583716869 3.5571338230511174e-05\n",
      "380 winrate= 0.56 0.06\n",
      "loss= 0.004712659399956465 0.004707437939941883 5.221456376602873e-06\n",
      "381 winrate= 0.65 0.04\n",
      "loss= 0.004854563623666763 0.004818027839064598 3.6535831895889714e-05\n",
      "382 winrate= 0.58 0.11\n",
      "loss= 0.004965231288224459 0.0049245585687458515 4.0672559407539666e-05\n",
      "383 winrate= 0.6 0.06\n",
      "loss= 0.00509134866297245 0.005024094134569168 6.725466664647684e-05\n",
      "384 winrate= 0.6 0.07\n",
      "loss= 0.004971948452293873 0.004946005530655384 2.5942948923329823e-05\n",
      "385 winrate= 0.55 0.08\n",
      "loss= 0.005029813386499882 0.004966657143086195 6.31564762443304e-05\n",
      "386 winrate= 0.63 0.05\n",
      "loss= 0.004999017342925072 0.0048131439834833145 0.00018587350496090949\n",
      "387 winrate= 0.55 0.07\n",
      "loss= 0.0053380257450044155 0.005009894259274006 0.00032813166035339236\n",
      "388 winrate= 0.64 0.06\n",
      "loss= 0.005029456689953804 0.004901621025055647 0.00012783556303475052\n",
      "389 winrate= 0.63 0.04\n",
      "loss= 0.005228227935731411 0.005115994717925787 0.00011223328328924254\n",
      "390 winrate= 0.53 0.06\n",
      "loss= 0.005072008352726698 0.004948670510202646 0.00012333779886830598\n",
      "391 winrate= 0.63 0.07\n",
      "loss= 0.0049337707459926605 0.004875043407082558 5.87271606491413e-05\n",
      "392 winrate= 0.72 0.05\n",
      "loss= 0.004819858819246292 0.004814505111426115 5.353581855160883e-06\n",
      "393 winrate= 0.64 0.07\n",
      "loss= 0.004960657097399235 0.004952284973114729 8.372156116820406e-06\n",
      "394 winrate= 0.67 0.05\n",
      "loss= 0.005147323943674564 0.005142941139638424 4.382578481454402e-06\n",
      "395 winrate= 0.6 0.09\n",
      "loss= 0.004987622611224651 0.004975189920514822 1.2432481526047923e-05\n",
      "396 winrate= 0.59 0.04\n",
      "loss= 0.004847283009439707 0.004837076645344496 1.0206317710981239e-05\n",
      "397 winrate= 0.57 0.1\n",
      "loss= 0.004938239231705666 0.0049344683066010475 3.770763214561157e-06\n",
      "398 winrate= 0.6 0.07\n",
      "loss= 0.005159469321370125 0.0051541756838560104 5.29362750967266e-06\n",
      "399 winrate= 0.53 0.1\n",
      "loss= 0.004707702901214361 0.004697293974459171 1.0408921298221685e-05\n",
      "400 winrate= 0.58 0.04\n",
      "loss= 0.004992444533854723 0.004986729007214308 5.715657152904896e-06\n",
      "401 winrate= 0.66 0.06\n",
      "loss= 0.005214674398303032 0.0052138580940663815 8.162149356394366e-07\n",
      "402 winrate= 0.61 0.09\n",
      "loss= 0.005006998777389526 0.00500096520408988 6.0335255511745345e-06\n",
      "403 winrate= 0.57 0.07\n",
      "loss= 0.005033191759139299 0.005028600804507732 4.590835487761069e-06\n",
      "404 winrate= 0.67 0.04\n",
      "loss= 0.005088452249765396 0.005070939660072327 1.751280069584027e-05\n",
      "405 winrate= 0.62 0.03\n",
      "loss= 0.00539358239620924 0.005249883513897657 0.00014369876589626074\n",
      "406 winrate= 0.59 0.05\n",
      "loss= 0.0051475223153829575 0.0049116769805550575 0.00023584550945088267\n",
      "407 winrate= 0.61 0.06\n",
      "loss= 0.005535582546144724 0.005193265154957771 0.0003423175076022744\n",
      "408 winrate= 0.65 0.05\n",
      "loss= 0.005357070825994015 0.005110071040689945 0.0002469998144079\n",
      "409 winrate= 0.57 0.05\n",
      "loss= 0.005194623488932848 0.005058847367763519 0.00013577620848082006\n",
      "410 winrate= 0.72 0.02\n",
      "loss= 0.004959446378052235 0.004936757031828165 2.2689386241836473e-05\n",
      "411 winrate= 0.59 0.08\n",
      "loss= 0.00510035827755928 0.005040764808654785 5.95932942815125e-05\n",
      "412 winrate= 0.68 0.06\n",
      "loss= 0.00506109232082963 0.004994136281311512 6.69559885864146e-05\n",
      "413 winrate= 0.68 0.06\n",
      "loss= 0.005011279601603746 0.004960808902978897 5.047062222729437e-05\n",
      "414 winrate= 0.62 0.06\n",
      "loss= 0.005124581512063742 0.005111814942210913 1.2766504369210452e-05\n",
      "415 winrate= 0.59 0.04\n",
      "loss= 0.005000770557671785 0.004963644780218601 3.712588659254834e-05\n",
      "416 winrate= 0.59 0.03\n",
      "loss= 0.005200653336942196 0.00517587224021554 2.478119859006256e-05\n",
      "417 winrate= 0.58 0.08\n",
      "loss= 0.005018012132495642 0.00498687569051981 3.113637649221346e-05\n",
      "418 winrate= 0.59 0.08\n",
      "loss= 0.004974879790097475 0.004943531937897205 3.134771395707503e-05\n",
      "419 winrate= 0.52 0.06\n",
      "loss= 0.0049271732568740845 0.0048811351880431175 4.603790875989944e-05\n",
      "420 winrate= 0.58 0.09\n",
      "loss= 0.0048968605697155 0.004874511621892452 2.2349069695337676e-05\n",
      "421 winrate= 0.59 0.06\n",
      "loss= 0.005078850779682398 0.0049716816283762455 0.0001071692822733894\n",
      "422 winrate= 0.64 0.08\n",
      "loss= 0.005040154326707125 0.004978324752300978 6.182953802635893e-05\n",
      "423 winrate= 0.6 0.08\n",
      "loss= 0.004974940791726112 0.004966025240719318 8.915647413232364e-06\n",
      "424 winrate= 0.58 0.09\n",
      "loss= 0.005087224300950766 0.005040932446718216 4.6291756007121876e-05\n",
      "425 winrate= 0.59 0.09\n",
      "loss= 0.004956472665071487 0.004943521693348885 1.2950808013556525e-05\n",
      "426 winrate= 0.64 0.06\n",
      "loss= 0.005031679291278124 0.004845418035984039 0.00018626141536515206\n",
      "427 winrate= 0.66 0.05\n",
      "loss= 0.005223775748163462 0.005151503253728151 7.227232708828524e-05\n",
      "428 winrate= 0.47 0.07\n",
      "loss= 0.005007264204323292 0.0050043086521327496 2.955573108920362e-06\n",
      "429 winrate= 0.65 0.05\n",
      "loss= 0.0050535365007817745 0.004911973141133785 0.00014156351971905679\n",
      "430 winrate= 0.57 0.08\n",
      "loss= 0.005252789705991745 0.005232830531895161 1.9958952179877087e-05\n",
      "431 winrate= 0.61 0.06\n",
      "loss= 0.0051452466286718845 0.005121300928294659 2.394551302131731e-05\n",
      "432 winrate= 0.52 0.08\n",
      "loss= 0.0049901255406439304 0.004953944589942694 3.6180739698465914e-05\n",
      "433 winrate= 0.6 0.07\n",
      "loss= 0.0048927729949355125 0.004856250248849392 3.6522797017823905e-05\n",
      "434 winrate= 0.63 0.11\n",
      "loss= 0.004942879546433687 0.004938813392072916 4.066345809405902e-06\n",
      "435 winrate= 0.58 0.07\n",
      "loss= 0.005115962587296963 0.005071728955954313 4.423361679073423e-05\n",
      "436 winrate= 0.61 0.06\n",
      "loss= 0.00510431220754981 0.005086495541036129 1.7816591935115866e-05\n",
      "437 winrate= 0.57 0.09\n",
      "loss= 0.004832857754081488 0.004831711295992136 1.1464795761639834e-06\n",
      "438 winrate= 0.66 0.09\n",
      "loss= 0.005028410814702511 0.005009081214666367 1.9329512724652886e-05\n",
      "439 winrate= 0.65 0.03\n",
      "loss= 0.005022733006626368 0.004988801199942827 3.3931893995031714e-05\n",
      "440 winrate= 0.58 0.06\n",
      "loss= 0.0052855475805699825 0.005254145711660385 3.140207991236821e-05\n",
      "441 winrate= 0.61 0.1\n",
      "loss= 0.005111070349812508 0.005099776200950146 1.1294000614725519e-05\n",
      "442 winrate= 0.52 0.07\n",
      "loss= 0.005023818928748369 0.0050069247372448444 1.6894231521291658e-05\n",
      "443 winrate= 0.62 0.06\n",
      "loss= 0.005081544164568186 0.0050717685371637344 9.775700164027512e-06\n",
      "444 winrate= 0.6 0.08\n",
      "loss= 0.005026822444051504 0.004982012789696455 4.480986171984114e-05\n",
      "445 winrate= 0.58 0.06\n",
      "loss= 0.005081282928586006 0.005041435360908508 3.9847793232183903e-05\n",
      "446 winrate= 0.59 0.07\n",
      "loss= 0.005132101476192474 0.005013109650462866 0.00011899171659024432\n",
      "447 winrate= 0.62 0.05\n",
      "loss= 0.005239289253950119 0.0050529902800917625 0.00018629901751410216\n",
      "448 winrate= 0.64 0.07\n",
      "loss= 0.005204315762966871 0.00498550571501255 0.0002188099460909143\n",
      "449 winrate= 0.56 0.1\n",
      "loss= 0.0052147661335766315 0.005063818767666817 0.00015094722039066255\n",
      "450 winrate= 0.59 0.08\n",
      "loss= 0.005185524467378855 0.005038953386247158 0.0001465708774048835\n",
      "451 winrate= 0.61 0.06\n",
      "loss= 0.004983589984476566 0.004956521559506655 2.7068244889960624e-05\n",
      "452 winrate= 0.59 0.05\n",
      "loss= 0.005068013444542885 0.005036990158259869 3.1023097108118236e-05\n",
      "453 winrate= 0.57 0.1\n",
      "loss= 0.005150696262717247 0.005141198169440031 9.497943210590165e-06\n",
      "454 winrate= 0.58 0.08\n",
      "loss= 0.005183014553040266 0.005181794986128807 1.2195592944408418e-06\n",
      "455 winrate= 0.57 0.05\n",
      "loss= 0.005068127065896988 0.005046825390309095 2.1301830201991834e-05\n",
      "456 winrate= 0.51 0.05\n",
      "loss= 0.004944271873682737 0.004928011912852526 1.6260139091173187e-05\n",
      "457 winrate= 0.54 0.11\n",
      "loss= 0.004972420632839203 0.004945671651512384 2.6749085009214468e-05\n",
      "458 winrate= 0.56 0.06\n",
      "loss= 0.005088216625154018 0.005080531816929579 7.684669981244951e-06\n",
      "459 winrate= 0.6 0.06\n",
      "loss= 0.005236385855823755 0.0052027227357029915 3.36629782395903e-05\n",
      "460 winrate= 0.57 0.06\n",
      "loss= 0.005210027564316988 0.005188317038118839 2.1710631699534133e-05\n",
      "461 winrate= 0.53 0.06\n",
      "loss= 0.005219962447881699 0.005174869671463966 4.509295104071498e-05\n",
      "462 winrate= 0.56 0.02\n",
      "loss= 0.005078412592411041 0.005049701314419508 2.8711225240840577e-05\n",
      "463 winrate= 0.65 0.03\n",
      "loss= 0.005053336266428232 0.0049965595826506615 5.677650187863037e-05\n",
      "464 winrate= 0.68 0.06\n",
      "loss= 0.00519466120749712 0.0051704649813473225 2.419602060399484e-05\n",
      "465 winrate= 0.55 0.07\n",
      "loss= 0.005207928828895092 0.005056119989603758 0.00015180872287601233\n",
      "466 winrate= 0.51 0.09\n",
      "loss= 0.005045824218541384 0.00492034200578928 0.00012548227095976472\n",
      "467 winrate= 0.54 0.06\n",
      "loss= 0.005268732085824013 0.005230932030826807 3.78000368073117e-05\n",
      "468 winrate= 0.58 0.03\n",
      "loss= 0.005461457185447216 0.005303081125020981 0.0001583759585628286\n",
      "469 winrate= 0.62 0.11\n",
      "loss= 0.0052622416988015175 0.005152896977961063 0.00010934477904811502\n",
      "470 winrate= 0.61 0.03\n",
      "loss= 0.005256989039480686 0.005177792627364397 7.919620838947594e-05\n",
      "471 winrate= 0.51 0.13\n",
      "loss= 0.005281640216708183 0.005266968626528978 1.467175388825126e-05\n",
      "472 winrate= 0.62 0.09\n",
      "loss= 0.0052587795071303844 0.005249050445854664 9.728852091939189e-06\n",
      "473 winrate= 0.66 0.05\n",
      "loss= 0.005067063495516777 0.005057698581367731 9.364748621010222e-06\n",
      "474 winrate= 0.53 0.06\n",
      "loss= 0.005092974286526442 0.005066265352070332 2.6708890800364316e-05\n",
      "475 winrate= 0.56 0.03\n",
      "loss= 0.00525244465097785 0.005234595853835344 1.7848862626124173e-05\n",
      "476 winrate= 0.62 0.09\n",
      "loss= 0.005337666254490614 0.00533380126580596 3.865184226015117e-06\n",
      "477 winrate= 0.6 0.04\n",
      "loss= 0.005381351802498102 0.005381065420806408 2.8643057703447994e-07\n",
      "478 winrate= 0.65 0.06\n",
      "loss= 0.005407185293734074 0.005389302037656307 1.7883152395370416e-05\n",
      "479 winrate= 0.64 0.04\n",
      "loss= 0.005071726161986589 0.005045420490205288 2.63056208495982e-05\n",
      "480 winrate= 0.61 0.07\n",
      "loss= 0.0051889559254050255 0.005169873125851154 1.9082723156316206e-05\n",
      "481 winrate= 0.62 0.08\n",
      "loss= 0.005094337277114391 0.0050743743777275085 1.996305218199268e-05\n",
      "482 winrate= 0.58 0.04\n",
      "loss= 0.0051655154675245285 0.005155345890671015 1.0169545021199156e-05\n",
      "483 winrate= 0.58 0.09\n",
      "loss= 0.005388106685131788 0.005366964731365442 2.114213384629693e-05\n",
      "484 winrate= 0.6 0.1\n",
      "loss= 0.005324113182723522 0.0052621010690927505 6.20119390077889e-05\n",
      "485 winrate= 0.63 0.06\n",
      "loss= 0.005216730758547783 0.00519978441298008 1.694640377536416e-05\n",
      "486 winrate= 0.66 0.08\n",
      "loss= 0.005257837008684874 0.0052460613660514355 1.1775848179240711e-05\n",
      "487 winrate= 0.65 0.08\n",
      "loss= 0.0052988543175160885 0.005201744846999645 9.710961603559554e-05\n",
      "488 winrate= 0.54 0.08\n",
      "loss= 0.0052690161392092705 0.005182468332350254 8.654760313220322e-05\n",
      "489 winrate= 0.54 0.07\n",
      "loss= 0.0052921362221241 0.005106231663376093 0.0001859047479229048\n",
      "490 winrate= 0.56 0.05\n",
      "loss= 0.005381252150982618 0.005343518685549498 3.7733592762378976e-05\n",
      "491 winrate= 0.58 0.1\n",
      "loss= 0.005263256374746561 0.005259211640805006 4.044875367981149e-06\n",
      "492 winrate= 0.6 0.08\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-f928e068768f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_simulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(nodes, state, policy, model, rollout_policy, value_function, neg_rew, cpucb, discount_factor)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m\"neither rollout_policy nor value_function specified\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpucb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_rew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstate2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mucb\u001b[0;34m(nodes, state, policy, model, cpucb, neg_rew)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mava\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmaxscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_maxscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mava\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/models.py\u001b[0m in \u001b[0;36mget_action_probs\u001b[0;34m(self, obs, available_actions)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs2testorobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobs2testorobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, available_actions)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_overrides.py\u001b[0m in \u001b[0;36mhas_torch_function\u001b[0;34m(relevant_args)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_overrides.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_env = TicTacToeEnv()\n",
    "obs = test_env.reset()\n",
    "\n",
    "test_env.render()\n",
    "# rbuff = ReplayBuffer(nitems=3, max_len=50*9)\n",
    "bsize = 128\n",
    "# wll.new()\n",
    "writer = wll.writer\n",
    "opt = torch.optim.Adam(list(tree_policy.parameters())+list(value_function.parameters()), lr=1e-2)\n",
    "# best_tree_policy = copy.deepcopy(tree_policy)\n",
    "# best_opt = copy.deepcopy(opt)\n",
    "# best_vfunc = copy.deepcopy(value_function)\n",
    "# game = 0\n",
    "n_simulations = 200\n",
    "temperature = 10\n",
    "rsize = 0\n",
    "\n",
    "for game_step in range(0, 10000):\n",
    "    obs = test_env.reset()\n",
    "    game_buff = [] \n",
    "    done = False\n",
    "    reward_sign = 1\n",
    "    while not done:\n",
    "        nodes = {obs:Node()}\n",
    "        for i in range(n_simulations):\n",
    "            mcts(nodes, obs, tree_policy, model, value_function=value_function, cpucb=50, discount_factor=0.99)\n",
    "        qs = get_qs(nodes, obs, model)\n",
    "        ns = get_ns(nodes, obs, model)\n",
    "\n",
    "        # print(ns)\n",
    "        monte_ns = torch.tensor(ns, dtype=torch.float).unsqueeze(0)/n_simulations\n",
    "        monte_probs = torch.softmax(monte_ns*temperature, dim=-1).detach()\n",
    "        # print(monte_probs)\n",
    "        tensor_obs = tree_policy.obs2testorobs(obs).unsqueeze(0)\n",
    "        tensor_rew_sign = torch.tensor([[reward_sign]])\n",
    "        game_buff.append((tensor_obs, monte_probs, tensor_rew_sign))\n",
    "        # print(monte_probs)\n",
    "        \n",
    "        move = get_best_action(nodes, obs, model)\n",
    "        obs, r, done, _ = test_env.step(move)\n",
    "        reward_sign *= -1\n",
    "    for tensor_obs, monte_probs, tensor_rew_sign in game_buff:\n",
    "        rbuff.add(tensor_obs, monte_probs, tensor_rew_sign*r)\n",
    "    # symetric_add2rbuff(rbuff, game_buff, rew_sign, r)\n",
    "\n",
    "    game += 1\n",
    "    if len(rbuff) <= bsize:\n",
    "        print(\"len rbuff=\", len(rbuff), len(game_buff))\n",
    "        continue   \n",
    "    rsize = 0  \n",
    "        \n",
    "    for step in range(2*(len(rbuff)//bsize+1)):\n",
    "        tensor_obs, monte_probs, game_finish = rbuff.get(bsize)\n",
    "        # print(tensor_obs.shape, monte_probs.shape, game_finish.shape)\n",
    "        # print(tensor_obs, monte_probs, game_finish)\n",
    "        for opt_step in range(4):\n",
    "            policy_probs = tree_policy(tensor_obs)\n",
    "            loss_policy = -(monte_probs*torch.log(policy_probs+1e-8)).mean()*10\n",
    "            loss_value  = ((value_function(tensor_obs)-game_finish)**2).mean()\n",
    "            loss = loss_policy + loss_value\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    print(\"loss=\", loss.item(), loss_policy.item(), loss_value.item())\n",
    "    writer.add_scalar('loss/loss', loss.item(), game_step)\n",
    "    writer.add_scalar('loss/policy', loss_policy.item(), game_step)\n",
    "    writer.add_scalar('loss/vfunc', loss_value.item(), game_step)\n",
    "    # writer.add_scalar('loss/game', game, game_step)\n",
    "\n",
    "    # if game % 7 == 0:\n",
    "    #     tree_policy.temperature, best_tree_policy.temperature = 1, 1\n",
    "    #     winrate, drawrate, loserate = eval_winrate(tree_policy, best_tree_policy, test_env, n_games=100)\n",
    "    #     tree_policy.temperature, best_tree_policy.temperature = 0.1, 0.1\n",
    "    #     print(\"ARENA!!! \", winrate, drawrate, loserate)\n",
    "    #     if winrate > loserate:\n",
    "    #         best_tree_policy = copy.deepcopy(tree_policy)\n",
    "    #         best_opt = copy.deepcopy(opt)\n",
    "    #         best_vfunc = copy.deepcopy(value_function)\n",
    "    #         print(\"upgrade\", winrate, drawrate, loserate)\n",
    "    #         winrate, drawrate, _ = eval_winrate(tree_policy, rollout_policy, test_env, n_games=300)\n",
    "    #         print(\"winrate against random \", winrate, drawrate)\n",
    "    #     else:\n",
    "    #         tree_policy = copy.deepcopy(best_tree_policy)\n",
    "    #         opt = copy.deepcopy(best_opt)\n",
    "    #         value_function = copy.deepcopy(best_vfunc)\n",
    "\n",
    "        \n",
    "    winrate2, drawrate2, _ = eval_winrate(tree_policy, rollout_policy, test_env, model, n_games=100)\n",
    "    writer.add_scalar('winrate/winrate', winrate2, game)\n",
    "    writer.add_scalar('winrate/drawrate', drawrate2, game)\n",
    "    print(game, \"winrate=\", winrate2, drawrate2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  O|X|O\n  -----\n   | | \n  -----\n  X| | \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, -0.6840388178825378)"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "env = TicTacToeEnv()\n",
    "obs = env.reset()\n",
    "env.step(0)\n",
    "env.step(1)\n",
    "# env.step(4)\n",
    "env.step(2)\n",
    "obs, _, _, _ = env.step(6)\n",
    "obs, _, _, _ = env.step(2)\n",
    "env.render()\n",
    "\n",
    "\n",
    "tree_policy.act(obs, model.available_actions(obs)), value_function.get(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2.1998e-05, 2.1533e-03, 4.5727e-06, 1.1061e-02, 1.2088e-01, 2.0388e-04,\n",
       "         7.7113e-04, 5.1501e-01, 3.4989e-01]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "tree_policy(tree_policy.obs2testorobs(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 4, 5, 7, 8]"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "model.available_actions(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(tree_policy, 'TicTacToe_policy', 1, 0)\n",
    "save(value_function, 'TicTacToe_value', 1, 0)\n",
    "save(opt, 'TicTacToe_opt', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_model_against_human(env, model, policy, value_function, human='first'):\n",
    "    obs = env.reset()\n",
    "    env.render()\n",
    "    done = False\n",
    "    turn = 0\n",
    "    human = 0 if human=='first' else 1 \n",
    "    while not done:\n",
    "        print(\"-\"*20)\n",
    "        env.render()\n",
    "        print(\"turn number\", turn)\n",
    "        print(\"value of position = \", value_function.get(obs))\n",
    "        if human == turn%2:\n",
    "            besta = int(input(\"your play? \"))\n",
    "            print(\"your action was\", besta)\n",
    "            obs, r, done, _ = env.step(besta)\n",
    "        else:\n",
    "            besta = policy.act(obs, model.available_actions(obs))\n",
    "            obs, r, done, _ = env.step(besta)\n",
    "        turn += 1\n",
    "    print(\"-\"*20)\n",
    "    env.render()    \n",
    "    print(\"final reward=\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "--------------------\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "turn number 0\n",
      "value of position =  1.005598783493042\n",
      "--------------------\n",
      "   | |O\n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "turn number 1\n",
      "value of position =  -1.0068035125732422\n",
      "your action was 4\n",
      "--------------------\n",
      "   | |O\n",
      "  -----\n",
      "   |X| \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "turn number 2\n",
      "value of position =  0.8598470687866211\n",
      "--------------------\n",
      "   | |O\n",
      "  -----\n",
      "   |X|O\n",
      "  -----\n",
      "   | | \n",
      "\n",
      "turn number 3\n",
      "value of position =  -0.7394993305206299\n",
      "your action was 8\n",
      "--------------------\n",
      "   | |O\n",
      "  -----\n",
      "   |X|O\n",
      "  -----\n",
      "   | |X\n",
      "\n",
      "turn number 4\n",
      "value of position =  1.0248593091964722\n",
      "--------------------\n",
      "   | |O\n",
      "  -----\n",
      "  O|X|O\n",
      "  -----\n",
      "   | |X\n",
      "\n",
      "turn number 5\n",
      "value of position =  0.06275974959135056\n",
      "your action was 0\n",
      "--------------------\n",
      "  X| |O\n",
      "  -----\n",
      "  O|X|O\n",
      "  -----\n",
      "   | |X\n",
      "\n",
      "final reward= -1\n"
     ]
    }
   ],
   "source": [
    "play_model_against_human(env, model, tree_policy, value_function, human='nas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}