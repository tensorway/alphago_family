{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitd95df06ad6614d8ea31ce2c635a29972",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9713480454050764"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import torch\n",
    "from alpha_zero.utils import eval_winrate\n",
    "from alpha_zero.models import RolloutPolicy, Model, Backbone, ValueFunction, NNTreePolicy, TreePolicy\n",
    "from alpha_zero.mcts import mcts, Node, get_ns, get_qs, get_best_action\n",
    "from alpha_zero.augmentations_tictactoe import symetric_add2rbuff\n",
    "from myrl.buffers import ReplayBuffer\n",
    "from myrl.utils import ExperimentWriter\n",
    "from gym_tictactoe.env import TicTacToeEnv, agent_by_mark, next_mark\n",
    "import copy\n",
    "from alpha_zero.utils import play_mcts_against_human, play_mcts_against_itself, save, load, play_model_against_human\n",
    "\n",
    "\n",
    "env = TicTacToeEnv()\n",
    "obs = env.reset()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import math\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_policy = RolloutPolicy(env)\n",
    "model = Model(TicTacToeEnv())\n",
    "backbone = Backbone([10, 32])\n",
    "value_function = ValueFunction([32, 16, 1], backbone=backbone)\n",
    "tree_policy = NNTreePolicy([32, 16, 9], backbone=backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.46, 0.1, 0.44000000000000006)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "eval_winrate(rollout_policy, tree_policy, TicTacToeEnv(), model, n_games=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_policy = copy.deepcopy(tree_policy)\n",
    "wll = ExperimentWriter('tb/alpha_tictacte_egreedy_explore_arena___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "018\n",
      "379 winrate= 0.68 0.02\n",
      "loss= 3.6435694694519043 0.09263595193624496 3.550933599472046\n",
      "380 winrate= 0.73 0.03\n",
      "loss= 2.7076313495635986 0.09353616833686829 2.6140952110290527\n",
      "381 winrate= 0.76 0.03\n",
      "loss= 2.9721243381500244 0.08649469912052155 2.885629653930664\n",
      "382 winrate= 0.62 0.09\n",
      "loss= 2.733546018600464 0.08592704683542252 2.6476190090179443\n",
      "383 winrate= 0.79 0.02\n",
      "loss= 1.4606837034225464 0.08749023079872131 1.3731935024261475\n",
      "384 winrate= 0.71 0.05\n",
      "loss= 1.930840253829956 0.10789040476083755 1.8229498863220215\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7433333333333333 0.03333333333333333\n",
      "385 winrate= 0.69 0.05\n",
      "loss= 3.005021572113037 0.1100187599658966 2.895002841949463\n",
      "386 winrate= 0.7 0.06\n",
      "loss= 2.9385101795196533 0.09222414344549179 2.8462860584259033\n",
      "387 winrate= 0.68 0.04\n",
      "loss= 2.241718053817749 0.07567187398672104 2.166046142578125\n",
      "388 winrate= 0.65 0.03\n",
      "loss= 3.12062668800354 0.09821098297834396 3.0224156379699707\n",
      "389 winrate= 0.64 0.08\n",
      "loss= 2.866065740585327 0.14732183516025543 2.7187438011169434\n",
      "390 winrate= 0.71 0.03\n",
      "loss= 2.688403367996216 0.09336365759372711 2.5950396060943604\n",
      "391 winrate= 0.75 0.03\n",
      "loss= 2.7997169494628906 0.0885143131017685 2.711202621459961\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6666666666666666 0.05\n",
      "392 winrate= 0.68 0.07\n",
      "loss= 1.5572155714035034 0.07985469698905945 1.4773608446121216\n",
      "393 winrate= 0.68 0.06\n",
      "loss= 2.3050167560577393 0.09700934588909149 2.208007335662842\n",
      "394 winrate= 0.75 0.05\n",
      "loss= 2.2591540813446045 0.09307032823562622 2.166083812713623\n",
      "395 winrate= 0.61 0.05\n",
      "loss= 1.968984603881836 0.09996795654296875 1.8690166473388672\n",
      "396 winrate= 0.76 0.05\n",
      "loss= 2.585787296295166 0.11471807956695557 2.4710693359375\n",
      "397 winrate= 0.74 0.03\n",
      "loss= 2.4160923957824707 0.0821693018078804 2.333923101425171\n",
      "398 winrate= 0.7 0.07\n",
      "loss= 3.012747287750244 0.10602237284183502 2.9067249298095703\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.68 0.04666666666666667\n",
      "399 winrate= 0.71 0.05\n",
      "loss= 2.7259318828582764 0.08234301209449768 2.6435887813568115\n",
      "400 winrate= 0.7 0.07\n",
      "loss= 2.4442086219787598 0.10347922146320343 2.3407294750213623\n",
      "401 winrate= 0.7 0.05\n",
      "loss= 2.2162277698516846 0.08487012982368469 2.1313576698303223\n",
      "402 winrate= 0.7 0.09\n",
      "loss= 2.143826484680176 0.10545817762613297 2.0383682250976562\n",
      "403 winrate= 0.84 0.03\n",
      "loss= 2.642307758331299 0.11489444226026535 2.5274133682250977\n",
      "404 winrate= 0.67 0.06\n",
      "loss= 3.526217460632324 0.11851697415113449 3.407700538635254\n",
      "405 winrate= 0.69 0.02\n",
      "loss= 2.7018861770629883 0.08793589472770691 2.613950252532959\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.73 0.056666666666666664\n",
      "406 winrate= 0.69 0.06\n",
      "loss= 3.320345163345337 0.09359986335039139 3.226745367050171\n",
      "407 winrate= 0.76 0.03\n",
      "loss= 2.726445436477661 0.09172515571117401 2.6347203254699707\n",
      "408 winrate= 0.75 0.04\n",
      "loss= 3.290511131286621 0.08316823840141296 3.2073428630828857\n",
      "409 winrate= 0.73 0.03\n",
      "loss= 3.1591954231262207 0.11678937077522278 3.0424060821533203\n",
      "410 winrate= 0.67 0.05\n",
      "loss= 2.2478156089782715 0.11963652074337006 2.1281790733337402\n",
      "411 winrate= 0.73 0.04\n",
      "loss= 3.0664315223693848 0.10469290614128113 2.9617385864257812\n",
      "412 winrate= 0.72 0.03\n",
      "loss= 2.476651430130005 0.10088548064231873 2.3757660388946533\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7233333333333334 0.05\n",
      "413 winrate= 0.66 0.08\n",
      "loss= 3.2573225498199463 0.17167837917804718 3.085644245147705\n",
      "414 winrate= 0.67 0.07\n",
      "loss= 2.624732732772827 0.10545376688241959 2.5192790031433105\n",
      "415 winrate= 0.77 0.07\n",
      "loss= 2.6616389751434326 0.11690703779459 2.544731855392456\n",
      "416 winrate= 0.72 0.07\n",
      "loss= 2.1804678440093994 0.0831994116306305 2.0972683429718018\n",
      "417 winrate= 0.73 0.04\n",
      "loss= 1.8431665897369385 0.10516715794801712 1.737999439239502\n",
      "418 winrate= 0.72 0.02\n",
      "loss= 2.611272096633911 0.10924529284238815 2.5020267963409424\n",
      "419 winrate= 0.66 0.07\n",
      "loss= 2.865513324737549 0.1182645708322525 2.747248649597168\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.05333333333333334\n",
      "420 winrate= 0.68 0.08\n",
      "loss= 1.5731805562973022 0.07986834645271301 1.4933122396469116\n",
      "421 winrate= 0.69 0.02\n",
      "loss= 2.2915897369384766 0.10394798219203949 2.1876418590545654\n",
      "422 winrate= 0.77 0.06\n",
      "loss= 1.952554702758789 0.10952895879745483 1.8430256843566895\n",
      "423 winrate= 0.7 0.06\n",
      "loss= 2.661175012588501 0.10090044140815735 2.560274600982666\n",
      "424 winrate= 0.69 0.04\n",
      "loss= 2.5423851013183594 0.10674066096544266 2.4356443881988525\n",
      "425 winrate= 0.64 0.02\n",
      "loss= 2.51897931098938 0.12493345141410828 2.394045829772949\n",
      "426 winrate= 0.71 0.04\n",
      "loss= 1.8053343296051025 0.06824224442243576 1.737092137336731\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7366666666666667 0.06\n",
      "427 winrate= 0.72 0.04\n",
      "loss= 2.4279160499572754 0.09865889698266983 2.3292572498321533\n",
      "428 winrate= 0.79 0.01\n",
      "loss= 1.5368390083312988 0.05479244887828827 1.4820466041564941\n",
      "429 winrate= 0.67 0.04\n",
      "loss= 1.4377758502960205 0.08798909932374954 1.3497867584228516\n",
      "430 winrate= 0.64 0.07\n",
      "loss= 2.1438047885894775 0.12312690168619156 2.0206778049468994\n",
      "431 winrate= 0.58 0.08\n",
      "loss= 1.7010747194290161 0.10665715485811234 1.5944175720214844\n",
      "432 winrate= 0.71 0.06\n",
      "loss= 2.446648597717285 0.09665673226118088 2.349991798400879\n",
      "433 winrate= 0.67 0.04\n",
      "loss= 2.8088741302490234 0.12544958293437958 2.683424472808838\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6666666666666666 0.04\n",
      "434 winrate= 0.75 0.07\n",
      "loss= 2.158159017562866 0.08385244756937027 2.0743064880371094\n",
      "435 winrate= 0.65 0.06\n",
      "loss= 2.5875496864318848 0.10303013026714325 2.4845194816589355\n",
      "436 winrate= 0.75 0.04\n",
      "loss= 2.492229461669922 0.11347770690917969 2.378751754760742\n",
      "437 winrate= 0.75 0.03\n",
      "loss= 2.0755441188812256 0.07125087082386017 2.004293203353882\n",
      "438 winrate= 0.66 0.08\n",
      "loss= 2.6008102893829346 0.12817642092704773 2.4726338386535645\n",
      "439 winrate= 0.71 0.06\n",
      "loss= 2.0671751499176025 0.09339658170938492 1.9737786054611206\n",
      "440 winrate= 0.74 0.02\n",
      "loss= 1.4965505599975586 0.09918703138828278 1.397363543510437\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.05333333333333334\n",
      "441 winrate= 0.71 0.06\n",
      "loss= 2.3722474575042725 0.09035782516002655 2.2818896770477295\n",
      "442 winrate= 0.67 0.05\n",
      "loss= 1.6970562934875488 0.09859180450439453 1.5984644889831543\n",
      "443 winrate= 0.72 0.06\n",
      "loss= 2.2530956268310547 0.09772197157144547 2.1553735733032227\n",
      "444 winrate= 0.76 0.05\n",
      "loss= 3.0641636848449707 0.12015727162361145 2.9440064430236816\n",
      "445 winrate= 0.67 0.02\n",
      "loss= 2.5577213764190674 0.1203753650188446 2.4373459815979004\n",
      "446 winrate= 0.71 0.06\n",
      "loss= 2.2931408882141113 0.06837573647499084 2.2247650623321533\n",
      "447 winrate= 0.68 0.04\n",
      "loss= 2.28691029548645 0.15223827958106995 2.134671926498413\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.64 0.08333333333333333\n",
      "448 winrate= 0.65 0.07\n",
      "loss= 3.4091930389404297 0.09652899950742722 3.312664031982422\n",
      "449 winrate= 0.73 0.03\n",
      "loss= 2.7104554176330566 0.13237914443016052 2.5780763626098633\n",
      "450 winrate= 0.61 0.05\n",
      "loss= 1.921706199645996 0.09064790606498718 1.8310582637786865\n",
      "451 winrate= 0.69 0.07\n",
      "loss= 2.827554941177368 0.10735262930393219 2.7202022075653076\n",
      "452 winrate= 0.62 0.07\n",
      "loss= 2.7752575874328613 0.12562379240989685 2.6496338844299316\n",
      "453 winrate= 0.73 0.09\n",
      "loss= 2.773174524307251 0.08733788132667542 2.6858365535736084\n",
      "454 winrate= 0.68 0.09\n",
      "loss= 3.799346923828125 0.13616617023944855 3.6631808280944824\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7 0.04666666666666667\n",
      "455 winrate= 0.68 0.05\n",
      "loss= 2.7700579166412354 0.11286412179470062 2.657193899154663\n",
      "456 winrate= 0.59 0.09\n",
      "loss= 2.161285877227783 0.12226784229278564 2.039018154144287\n",
      "457 winrate= 0.74 0.03\n",
      "loss= 2.217005491256714 0.12201783061027527 2.094987630844116\n",
      "458 winrate= 0.68 0.07\n",
      "loss= 3.0485026836395264 0.10577508062124252 2.942727565765381\n",
      "459 winrate= 0.57 0.08\n",
      "loss= 3.563812732696533 0.09533032029867172 3.468482494354248\n",
      "460 winrate= 0.64 0.04\n",
      "loss= 1.9697132110595703 0.09863641858100891 1.8710768222808838\n",
      "461 winrate= 0.68 0.07\n",
      "loss= 1.7521404027938843 0.06537720561027527 1.6867631673812866\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6733333333333333 0.056666666666666664\n",
      "462 winrate= 0.7 0.04\n",
      "loss= 2.631509780883789 0.10723397135734558 2.524275779724121\n",
      "463 winrate= 0.64 0.04\n",
      "loss= 1.999456763267517 0.07730451226234436 1.9221522808074951\n",
      "464 winrate= 0.63 0.06\n",
      "loss= 2.4937517642974854 0.09009532630443573 2.403656482696533\n",
      "465 winrate= 0.67 0.03\n",
      "loss= 2.8553552627563477 0.12557929754257202 2.729775905609131\n",
      "466 winrate= 0.76 0.04\n",
      "loss= 3.0786194801330566 0.06878015398979187 3.0098392963409424\n",
      "467 winrate= 0.7 0.05\n",
      "loss= 2.870244026184082 0.0753302276134491 2.7949137687683105\n",
      "468 winrate= 0.71 0.03\n",
      "loss= 2.63653302192688 0.10061272978782654 2.5359203815460205\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6966666666666667 0.06333333333333334\n",
      "469 winrate= 0.73 0.01\n",
      "loss= 1.7515709400177002 0.07423451542854309 1.6773364543914795\n",
      "470 winrate= 0.73 0.07\n",
      "loss= 2.419398784637451 0.09490153193473816 2.3244972229003906\n",
      "471 winrate= 0.67 0.03\n",
      "loss= 3.2022647857666016 0.07595085352659225 3.1263139247894287\n",
      "472 winrate= 0.71 0.06\n",
      "loss= 1.8986639976501465 0.10819471627473831 1.7904692888259888\n",
      "473 winrate= 0.71 0.07\n",
      "loss= 2.020719051361084 0.11288473010063171 1.9078342914581299\n",
      "474 winrate= 0.69 0.04\n",
      "loss= 2.2828192710876465 0.1005186066031456 2.182300567626953\n",
      "475 winrate= 0.73 0.08\n",
      "loss= 1.7349780797958374 0.08482178300619125 1.6501562595367432\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6933333333333334 0.06333333333333334\n",
      "476 winrate= 0.73 0.05\n",
      "loss= 2.504513740539551 0.0996847152709961 2.4048290252685547\n",
      "477 winrate= 0.7 0.02\n",
      "loss= 2.242677688598633 0.12243887782096863 2.120238780975342\n",
      "478 winrate= 0.73 0.05\n",
      "loss= 2.9583568572998047 0.07719465345144272 2.881162166595459\n",
      "479 winrate= 0.72 0.11\n",
      "loss= 1.9171253442764282 0.10829072445631027 1.8088346719741821\n",
      "480 winrate= 0.7 0.03\n",
      "loss= 3.0570812225341797 0.11142434179782867 2.9456567764282227\n",
      "481 winrate= 0.7 0.05\n",
      "loss= 2.2192885875701904 0.09580717980861664 2.123481512069702\n",
      "482 winrate= 0.74 0.04\n",
      "loss= 2.026108980178833 0.12544970214366913 1.9006593227386475\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7166666666666667 0.05\n",
      "483 winrate= 0.72 0.02\n",
      "loss= 2.42763090133667 0.12730933725833893 2.300321578979492\n",
      "484 winrate= 0.72 0.05\n",
      "loss= 2.235638380050659 0.08770322054624557 2.147935152053833\n",
      "485 winrate= 0.66 0.1\n",
      "loss= 1.9059839248657227 0.11546501517295837 1.790518879890442\n",
      "486 winrate= 0.76 0.01\n",
      "loss= 3.001333475112915 0.09637997299432755 2.9049534797668457\n",
      "487 winrate= 0.72 0.05\n",
      "loss= 1.979986548423767 0.1271594613790512 1.8528270721435547\n",
      "488 winrate= 0.63 0.04\n",
      "loss= 2.536639928817749 0.1211090236902237 2.4155309200286865\n",
      "489 winrate= 0.69 0.05\n",
      "loss= 2.9335103034973145 0.08521049469709396 2.848299741744995\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.03333333333333333\n",
      "490 winrate= 0.72 0.03\n",
      "loss= 2.2919933795928955 0.10942357778549194 2.182569742202759\n",
      "491 winrate= 0.69 0.03\n",
      "loss= 2.3209593296051025 0.07919584214687347 2.2417635917663574\n",
      "492 winrate= 0.61 0.03\n",
      "loss= 1.6046375036239624 0.09217103570699692 1.5124664306640625\n",
      "493 winrate= 0.67 0.08\n",
      "loss= 3.131465435028076 0.09422600269317627 3.0372395515441895\n",
      "494 winrate= 0.69 0.03\n",
      "loss= 1.5465359687805176 0.13407155871391296 1.4124643802642822\n",
      "495 winrate= 0.72 0.08\n",
      "loss= 2.136284589767456 0.06803879886865616 2.0682458877563477\n",
      "496 winrate= 0.74 0.01\n",
      "loss= 1.7566454410552979 0.065564826130867 1.6910805702209473\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6766666666666666 0.06333333333333334\n",
      "497 winrate= 0.76 0.03\n",
      "loss= 1.6077739000320435 0.09445308148860931 1.513320803642273\n",
      "498 winrate= 0.71 0.06\n",
      "loss= 2.3084092140197754 0.08047473430633545 2.2279343605041504\n",
      "499 winrate= 0.63 0.08\n",
      "loss= 3.0822339057922363 0.09613469988107681 2.9860992431640625\n",
      "500 winrate= 0.74 0.06\n",
      "loss= 2.4957547187805176 0.11518716812133789 2.3805675506591797\n",
      "501 winrate= 0.67 0.06\n",
      "loss= 2.253406524658203 0.10100862383842468 2.152397871017456\n",
      "502 winrate= 0.63 0.06\n",
      "loss= 2.946962833404541 0.09730827063322067 2.8496546745300293\n",
      "503 winrate= 0.63 0.08\n",
      "loss= 2.8232080936431885 0.07542311400175095 2.7477850914001465\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.05333333333333334\n",
      "504 winrate= 0.71 0.04\n",
      "loss= 2.3012120723724365 0.09303664416074753 2.2081754207611084\n",
      "505 winrate= 0.7 0.04\n",
      "loss= 2.0488367080688477 0.09885582327842712 1.9499809741973877\n",
      "506 winrate= 0.73 0.05\n",
      "loss= 1.644129991531372 0.06405182182788849 1.580078125\n",
      "507 winrate= 0.62 0.09\n",
      "loss= 2.6161460876464844 0.07374245673418045 2.5424036979675293\n",
      "508 winrate= 0.71 0.01\n",
      "loss= 1.423031210899353 0.09916500002145767 1.3238662481307983\n",
      "509 winrate= 0.62 0.04\n",
      "loss= 1.6866819858551025 0.08053281903266907 1.6061491966247559\n",
      "510 winrate= 0.67 0.03\n",
      "loss= 2.1717529296875 0.07809573411941528 2.0936572551727295\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.04\n",
      "511 winrate= 0.7 0.04\n",
      "loss= 1.3216406106948853 0.08396865427494049 1.237671971321106\n",
      "512 winrate= 0.71 0.08\n",
      "loss= 1.2660764455795288 0.0866231769323349 1.1794532537460327\n",
      "513 winrate= 0.7 0.03\n",
      "loss= 2.354729413986206 0.07327090203762054 2.281458616256714\n",
      "514 winrate= 0.69 0.05\n",
      "loss= 2.0744316577911377 0.12757523357868195 1.9468563795089722\n",
      "515 winrate= 0.72 0.08\n",
      "loss= 1.8027700185775757 0.08008943498134613 1.7226805686950684\n",
      "516 winrate= 0.66 0.05\n",
      "loss= 1.9611176252365112 0.10234500467777252 1.8587726354599\n",
      "517 winrate= 0.75 0.05\n",
      "loss= 2.4811227321624756 0.06775781512260437 2.413364887237549\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.71 0.06666666666666667\n",
      "518 winrate= 0.64 0.09\n",
      "loss= 2.0876753330230713 0.10637383908033371 1.9813015460968018\n",
      "519 winrate= 0.71 0.04\n",
      "loss= 2.2959656715393066 0.10002245754003525 2.1959431171417236\n",
      "520 winrate= 0.67 0.03\n",
      "loss= 2.3448894023895264 0.09978846460580826 2.245100975036621\n",
      "521 winrate= 0.77 0.07\n",
      "loss= 2.1484758853912354 0.09227600693702698 2.056199789047241\n",
      "522 winrate= 0.74 0.05\n",
      "loss= 2.4581212997436523 0.09110405296087265 2.3670172691345215\n",
      "523 winrate= 0.7 0.06\n",
      "loss= 2.3077776432037354 0.08379936963319778 2.223978281021118\n",
      "524 winrate= 0.77 0.03\n",
      "loss= 2.130573034286499 0.06070193275809288 2.069871187210083\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7033333333333334 0.06\n",
      "525 winrate= 0.65 0.03\n",
      "loss= 2.4184298515319824 0.10366279631853104 2.3147671222686768\n",
      "526 winrate= 0.69 0.08\n",
      "loss= 2.342839479446411 0.0629289299249649 2.2799105644226074\n",
      "527 winrate= 0.71 0.04\n",
      "loss= 2.5398476123809814 0.1059686541557312 2.4338788986206055\n",
      "528 winrate= 0.69 0.06\n",
      "loss= 2.385744094848633 0.12082180380821228 2.2649223804473877\n",
      "529 winrate= 0.66 0.08\n",
      "loss= 2.9361908435821533 0.14254631102085114 2.793644428253174\n",
      "530 winrate= 0.66 0.05\n",
      "loss= 2.901185989379883 0.10148242115974426 2.799703598022461\n",
      "531 winrate= 0.71 0.02\n",
      "loss= 2.986419916152954 0.12152460962533951 2.8648953437805176\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7066666666666667 0.03666666666666667\n",
      "532 winrate= 0.72 0.05\n",
      "loss= 2.778839588165283 0.101956307888031 2.6768832206726074\n",
      "533 winrate= 0.77 0.07\n",
      "loss= 3.2144229412078857 0.10868801176548004 3.1057348251342773\n",
      "534 winrate= 0.73 0.06\n",
      "loss= 2.955692768096924 0.1029193103313446 2.852773427963257\n",
      "535 winrate= 0.68 0.03\n",
      "loss= 2.41719913482666 0.10671216994524002 2.3104870319366455\n",
      "536 winrate= 0.69 0.05\n",
      "loss= 2.6308071613311768 0.13247565925121307 2.4983315467834473\n",
      "537 winrate= 0.79 0.02\n",
      "loss= 2.7889621257781982 0.07558594644069672 2.71337628364563\n",
      "538 winrate= 0.71 0.05\n",
      "loss= 2.79526686668396 0.11753800511360168 2.6777288913726807\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6866666666666666 0.04666666666666667\n",
      "539 winrate= 0.67 0.06\n",
      "loss= 2.816185712814331 0.08507206290960312 2.7311136722564697\n",
      "540 winrate= 0.71 0.05\n",
      "loss= 3.3721532821655273 0.1133173406124115 3.258836030960083\n",
      "541 winrate= 0.66 0.05\n",
      "loss= 3.260603427886963 0.07311755418777466 3.187485933303833\n",
      "542 winrate= 0.62 0.08\n",
      "loss= 2.535566568374634 0.12268601357936859 2.4128806591033936\n",
      "543 winrate= 0.67 0.04\n",
      "loss= 3.3300998210906982 0.11031293123960495 3.2197868824005127\n",
      "544 winrate= 0.67 0.06\n",
      "loss= 2.2209312915802 0.13632522523403168 2.084606170654297\n",
      "545 winrate= 0.68 0.03\n",
      "loss= 2.547358989715576 0.08040007948875427 2.466958999633789\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6833333333333333 0.04\n",
      "546 winrate= 0.7 0.06\n",
      "loss= 1.970018744468689 0.1331464946269989 1.8368722200393677\n",
      "547 winrate= 0.6 0.07\n",
      "loss= 3.4197938442230225 0.1741097867488861 3.2456841468811035\n",
      "548 winrate= 0.77 0.03\n",
      "loss= 2.5016210079193115 0.19062986969947815 2.310991048812866\n",
      "549 winrate= 0.69 0.06\n",
      "loss= 3.3342487812042236 0.16018754243850708 3.1740612983703613\n",
      "550 winrate= 0.58 0.07\n",
      "loss= 1.826513409614563 0.07644496858119965 1.7500684261322021\n",
      "551 winrate= 0.56 0.06\n",
      "loss= 3.886429786682129 0.15079015493392944 3.7356395721435547\n",
      "552 winrate= 0.69 0.07\n",
      "loss= 2.3383405208587646 0.09892544150352478 2.239415168762207\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.7066666666666667 0.05333333333333334\n",
      "553 winrate= 0.7 0.09\n",
      "loss= 2.1233224868774414 0.12407641857862473 1.9992461204528809\n",
      "554 winrate= 0.77 0.01\n",
      "loss= 2.024667978286743 0.07022067904472351 1.9544472694396973\n",
      "555 winrate= 0.71 0.07\n",
      "loss= 3.103342294692993 0.165692538022995 2.937649726867676\n",
      "556 winrate= 0.69 0.08\n",
      "loss= 1.6389784812927246 0.11639617383480072 1.5225822925567627\n",
      "557 winrate= 0.68 0.07\n",
      "loss= 2.62662410736084 0.15591038763523102 2.4707136154174805\n",
      "558 winrate= 0.75 0.02\n",
      "loss= 1.8367406129837036 0.10104694962501526 1.7356936931610107\n",
      "559 winrate= 0.72 0.07\n",
      "loss= 3.199038505554199 0.1630944162607193 3.0359439849853516\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.64 0.04666666666666667\n",
      "560 winrate= 0.7 0.03\n",
      "loss= 2.190800428390503 0.13518592715263367 2.055614471435547\n",
      "561 winrate= 0.72 0.05\n",
      "loss= 3.6851468086242676 0.10195164382457733 3.583195209503174\n",
      "562 winrate= 0.7 0.04\n",
      "loss= 1.743660807609558 0.10977169871330261 1.633889079093933\n",
      "563 winrate= 0.71 0.05\n",
      "loss= 1.8580174446105957 0.11300095170736313 1.7450164556503296\n",
      "564 winrate= 0.79 0.05\n",
      "loss= 2.024472713470459 0.11428582668304443 1.9101868867874146\n",
      "565 winrate= 0.66 0.04\n",
      "loss= 2.0420405864715576 0.1423022747039795 1.8997383117675781\n",
      "566 winrate= 0.74 0.07\n",
      "loss= 2.176671028137207 0.12266865372657776 2.054002285003662\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.6933333333333334 0.06333333333333334\n",
      "567 winrate= 0.69 0.03\n",
      "loss= 2.1834640502929688 0.15217657387256622 2.031287431716919\n",
      "568 winrate= 0.79 0.03\n",
      "loss= 1.7084553241729736 0.08488263189792633 1.6235727071762085\n",
      "569 winrate= 0.73 0.05\n",
      "loss= 2.2766878604888916 0.07177773118019104 2.2049100399017334\n",
      "570 winrate= 0.69 0.08\n",
      "loss= 2.294644832611084 0.1000228002667427 2.194622039794922\n",
      "571 winrate= 0.69 0.02\n",
      "loss= 2.489187479019165 0.11513132601976395 2.374056100845337\n",
      "572 winrate= 0.65 0.13\n",
      "loss= 2.15869140625 0.10224981606006622 2.05644154548645\n",
      "573 winrate= 0.67 0.04\n",
      "loss= 1.887632966041565 0.13558229804039001 1.7520506381988525\n",
      "ARENA!!!  0.51 0.0 0.49\n",
      "upgrade 0.51 0.0 0.49\n",
      "winrate against random  0.68 0.03\n",
      "574 winrate= 0.71 0.03\n",
      "loss= 2.8537795543670654 0.09335395693778992 2.760425567626953\n",
      "575 winrate= 0.76 0.04\n",
      "loss= 2.802273988723755 0.12245884537696838 2.6798150539398193\n",
      "576 winrate= 0.61 0.08\n",
      "loss= 2.0710859298706055 0.11464985460042953 1.956436038017273\n",
      "577 winrate= 0.81 0.04\n",
      "loss= 2.2831871509552 0.07651051878929138 2.206676721572876\n",
      "578 winrate= 0.68 0.06\n",
      "loss= 1.941561222076416 0.09323328733444214 1.848327875137329\n",
      "579 winrate= 0.7 0.06\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-eab0649dc497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_simulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(nodes, state, policy, model, rollout_policy, value_function, neg_rew, cpucb, discount_factor)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(nodes, state, policy, model, rollout_policy, value_function, neg_rew, cpucb, discount_factor)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiscount_factor\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mmcts\u001b[0;34m(nodes, state, policy, model, rollout_policy, value_function, neg_rew, cpucb, discount_factor)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m\"neither rollout_policy nor value_function specified\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpucb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_rew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstate2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/mcts.py\u001b[0m in \u001b[0;36mucb\u001b[0;34m(nodes, state, policy, model, cpucb, neg_rew)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpucb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_rew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mava\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmaxscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_maxscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mava\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/models.py\u001b[0m in \u001b[0;36mget_action_probs\u001b[0;34m(self, obs, available_actions)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_actions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs2testorobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobs2testorobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/githubs/alphago_family/alpha_zero/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, available_actions)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlay\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     \u001b[0mtens_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_overrides.py\u001b[0m in \u001b[0;36mhas_torch_function\u001b[0;34m(relevant_args)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_overrides.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \"\"\"\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_overridable_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_env = TicTacToeEnv()\n",
    "obs = test_env.reset()\n",
    "\n",
    "rbuff = ReplayBuffer(nitems=3, max_len=50*9)\n",
    "bsize = 64\n",
    "wll.new()\n",
    "writer = wll.writer\n",
    "opt = torch.optim.Adam(list(tree_policy.parameters())+list(value_function.parameters()), lr=1e-3)\n",
    "best_tree_policy = copy.deepcopy(tree_policy)\n",
    "best_opt = copy.deepcopy(opt)\n",
    "best_vfunc = copy.deepcopy(value_function)\n",
    "game = game_step\n",
    "n_simulations = 100\n",
    "temperature = 10\n",
    "rsize = 0\n",
    "\n",
    "for game_step in range(395, 10000):\n",
    "    obs = test_env.reset()\n",
    "    game_buff = []\n",
    "    done = False\n",
    "    while not done:\n",
    "        nodes = {obs:Node()}\n",
    "        for i in range(n_simulations):\n",
    "            mcts(nodes, obs, tree_policy, model, value_function=value_function, cpucb=50, discount_factor=0.99)\n",
    "        qs = get_qs(nodes, obs, model)\n",
    "        ns = get_ns(nodes, obs, model)\n",
    "\n",
    "        monte_ns = torch.tensor(ns, dtype=torch.float).unsqueeze(0)/n_simulations\n",
    "        monte_probs = torch.softmax(monte_ns*temperature, dim=-1).detach()\n",
    "        tensor_obs = tree_policy.obs2testorobs(obs).unsqueeze(0)\n",
    "        game_buff.append((tensor_obs, monte_probs))\n",
    "\n",
    "        if random.random() > max(0, min(1, 10/(game+1e-8))):\n",
    "            move = random.choice(model.available_actions(obs))\n",
    "        else:\n",
    "            move = get_best_action(nodes, obs, model)\n",
    "        obs, r, done, _ = test_env.step(move)\n",
    "\n",
    "    tensor_rew_sign = torch.ones(1, 1)*r\n",
    "    for tensor_obs, monte_probs in game_buff:\n",
    "        rbuff.add(tensor_obs, monte_probs, tensor_rew_sign)\n",
    "        tensor_rew_sign *= -1\n",
    "    # symetric_add2rbuff(rbuff, game_buff, rew_sign, r)\n",
    "\n",
    "    game += 1\n",
    "    if len(rbuff) <= bsize:\n",
    "        print(\"len rbuff=\", len(rbuff), len(game_buff))\n",
    "        continue\n",
    "    rsize = 0\n",
    "\n",
    "    for step in range(2*(len(rbuff)//bsize+1)):\n",
    "        tensor_obs, monte_probs, game_finish = rbuff.get(bsize)\n",
    "        # print(tensor_obs.shape, monte_probs.shape, game_finish.shape)\n",
    "        # print(tensor_obs, monte_probs, game_finish)\n",
    "        for opt_step in range(4):\n",
    "            policy_probs = tree_policy(tensor_obs)\n",
    "            loss_policy = -(monte_probs*torch.log(policy_probs+1e-8)).mean()\n",
    "            loss_value  = ((value_function(tensor_obs)-game_finish)**2).mean()*10\n",
    "            loss = loss_policy + loss_value\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    print(\"loss=\", loss.item(), loss_policy.item(), loss_value.item())\n",
    "    writer.add_scalar('loss/loss', loss.item(), game)\n",
    "    writer.add_scalar('loss/policy', loss_policy.item(), game)\n",
    "    writer.add_scalar('loss/vfunc', loss_value.item(), game)\n",
    "    # writer.add_scalar('loss/game', game, game_step)\n",
    "\n",
    "    if game % 7 == 0:\n",
    "        tree_policy.temperature, best_tree_policy.temperature = 0.1, 0.1\n",
    "        winrate, drawrate, loserate = eval_winrate(tree_policy, best_tree_policy, test_env, model, n_games=100)\n",
    "        tree_policy.temperature, best_tree_policy.temperature = 1, 1\n",
    "        print(\"ARENA!!! \", winrate, drawrate, loserate)\n",
    "        if winrate > loserate:\n",
    "            best_tree_policy = copy.deepcopy(tree_policy)\n",
    "            best_opt = copy.deepcopy(opt)\n",
    "            best_vfunc = copy.deepcopy(value_function)\n",
    "            print(\"upgrade\", winrate, drawrate, loserate)\n",
    "            winrate, drawrate, _ = eval_winrate(tree_policy, rollout_policy, test_env, model, n_games=300)\n",
    "            print(\"winrate against random \", winrate, drawrate)\n",
    "        else:\n",
    "            tree_policy = copy.deepcopy(best_tree_policy)\n",
    "            opt = copy.deepcopy(best_opt)\n",
    "            value_function = copy.deepcopy(best_vfunc)\n",
    "\n",
    "\n",
    "    winrate2, drawrate2, _ = eval_winrate(tree_policy, rollout_policy, test_env, model, n_games=100)\n",
    "    writer.add_scalar('winrate/winrate', winrate2, game)\n",
    "    writer.add_scalar('winrate/drawrate', drawrate2, game)\n",
    "    print(game, \"winrate=\", winrate2, drawrate2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "--------------------\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "\n",
      "turn number 0\n",
      "value of position =  -0.874956488609314\n",
      "--------------------\n",
      "   | | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 1\n",
      "value of position =  -0.827090859413147\n",
      "your action was 0\n",
      "--------------------\n",
      "  X| | \n",
      "  -----\n",
      "   | | \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 2\n",
      "value of position =  -0.9447544813156128\n",
      "--------------------\n",
      "  X| | \n",
      "  -----\n",
      "   |O| \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 3\n",
      "value of position =  -1.0376200675964355\n",
      "your action was 2\n",
      "--------------------\n",
      "  X| |X\n",
      "  -----\n",
      "   |O| \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 4\n",
      "value of position =  -0.8899586200714111\n",
      "--------------------\n",
      "  X|O|X\n",
      "  -----\n",
      "   |O| \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 5\n",
      "value of position =  -0.7020097970962524\n",
      "your action was 3\n",
      "--------------------\n",
      "  X|O|X\n",
      "  -----\n",
      "  X|O| \n",
      "  -----\n",
      "  O| | \n",
      "\n",
      "turn number 6\n",
      "value of position =  -1.099194049835205\n",
      "--------------------\n",
      "  X|O|X\n",
      "  -----\n",
      "  X|O| \n",
      "  -----\n",
      "  O|O| \n",
      "\n",
      "final reward= 1\n"
     ]
    }
   ],
   "source": [
    "play_model_against_human(env, model, tree_policy, value_function, human='firt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_policy.temperature = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}